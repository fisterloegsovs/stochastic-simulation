{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87aea1c5",
   "metadata": {},
   "source": [
    "# Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c576f405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3499d78e",
   "metadata": {},
   "source": [
    "## 1. Crude Monte Carlo for ∫₀¹ eˣ dx\n",
    "Estimate using n=100, report point estimate & 95% CI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5276ee67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate = 1.688072\n",
      "95% CI  = [1.588390, 1.787753]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: Crude MC\n",
    "n = 100\n",
    "u = np.random.rand(n)\n",
    "fx = np.exp(u)\n",
    "est1 = fx.mean()\n",
    "se1 = fx.std(ddof=1) / np.sqrt(n)\n",
    "ci1 = (est1 - 1.96*se1, est1 + 1.96*se1)\n",
    "print(f\"Estimate = {est1:.6f}\")\n",
    "print(f\"95% CI  = [{ci1[0]:.6f}, {ci1[1]:.6f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33367a77",
   "metadata": {},
   "source": [
    "## 2. Antithetic Variables\n",
    "Use u and 1−u, total 100 evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92567193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antithetic estimate = 1.716744\n",
      "95% CI            = [1.700109, 1.733379]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: Antithetic\n",
    "m = 50\n",
    "u = np.random.rand(m)\n",
    "fx2 = 0.5*(np.exp(u) + np.exp(1-u))\n",
    "est2 = fx2.mean()\n",
    "se2 = fx2.std(ddof=1) / np.sqrt(m)\n",
    "ci2 = (est2 - 1.96*se2, est2 + 1.96*se2)\n",
    "print(f\"Antithetic estimate = {est2:.6f}\")\n",
    "print(f\"95% CI            = [{ci2[0]:.6f}, {ci2[1]:.6f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d011882",
   "metadata": {},
   "source": [
    "## 3. Control Variate\n",
    "Use Y=u with E[Y]=0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f37791b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control variate est = 1.713477 (c=1.696)\n",
      "95% CI               = [1.701401, 1.725552]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: Control Variate\n",
    "n = 100\n",
    "u = np.random.rand(n)\n",
    "h = np.exp(u)\n",
    "c = np.cov(h, u, ddof=1)[0,1] / np.var(u, ddof=1)\n",
    "cv = h - c*(u - 0.5)\n",
    "est3 = cv.mean()\n",
    "se3 = cv.std(ddof=1) / np.sqrt(n)\n",
    "ci3 = (est3 - 1.96*se3, est3 + 1.96*se3)\n",
    "print(f\"Control variate est = {est3:.6f} (c={c:.3f})\")\n",
    "print(f\"95% CI               = [{ci3[0]:.6f}, {ci3[1]:.6f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7266f9bc",
   "metadata": {},
   "source": [
    "## 4. Stratified Sampling\n",
    "Divide [0,1] into 10 strata, 10 samples each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60ce3b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified est = 1.710992\n",
      "95% CI         = [1.396588, 2.025396]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: Stratified Sampling\n",
    "k = 10\n",
    "n_per = 10\n",
    "ests = []\n",
    "for i in range(k):\n",
    "    a, b = i/k, (i+1)/k\n",
    "    u = np.random.rand(n_per)*(b-a) + a\n",
    "    ests.append(np.exp(u).mean())\n",
    "est4 = np.mean(ests)\n",
    "se4 = np.std(ests, ddof=1)/np.sqrt(k)\n",
    "ci4 = (est4 - 1.96*se4, est4 + 1.96*se4)\n",
    "print(f\"Stratified est = {est4:.6f}\")\n",
    "print(f\"95% CI         = [{ci4[0]:.6f}, {ci4[1]:.6f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91205696",
   "metadata": {},
   "source": [
    "## 5. Control Variate for Poisson Arrivals\n",
    "Use control variates to reduce variance of blocking estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58bf4e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated blocking fraction (with CV): 0.1191\n",
      "95% CI: (0.1174, 0.1208)\n"
     ]
    }
   ],
   "source": [
    "def simulate_blocking_with_control_variate(servers=10, svc_mean=8, ia_mean=1, arrivals=10000):\n",
    "    t_now = 0.0\n",
    "    block_flags = []\n",
    "    busy_history = []\n",
    "    end_times = []\n",
    "\n",
    "    for _ in range(arrivals):\n",
    "        # generate next arrival time\n",
    "        ia = np.random.exponential(scale=ia_mean)\n",
    "        t_now += ia\n",
    "\n",
    "        # remove finished services\n",
    "        end_times = [et for et in end_times if et > t_now]\n",
    "\n",
    "        busy = len(end_times)\n",
    "        busy_history.append(busy)\n",
    "\n",
    "        if busy < servers:\n",
    "            # schedule service completion\n",
    "            st = np.random.exponential(scale=svc_mean)\n",
    "            end_times.append(t_now + st)\n",
    "            block_flags.append(0)\n",
    "        else:\n",
    "            # arrival dropped\n",
    "            block_flags.append(1)\n",
    "\n",
    "    return np.array(block_flags), np.array(busy_history)\n",
    "\n",
    "\n",
    "# perform multiple independent runs\n",
    "runs = 10\n",
    "all_blocks = []\n",
    "all_busy = []\n",
    "\n",
    "for _ in range(runs):\n",
    "    blocks, busy = simulate_blocking_with_control_variate()\n",
    "    all_blocks.append(blocks)\n",
    "    all_busy.append(busy)\n",
    "\n",
    "# stack results from all runs\n",
    "blocks = np.hstack(all_blocks)\n",
    "busy = np.hstack(all_busy)\n",
    "\n",
    "# compute control variate parameter theta\n",
    "cov_matrix = np.cov(blocks, busy, ddof=1)\n",
    "cov_b_busy = cov_matrix[0, 1]\n",
    "var_busy    = cov_matrix[1, 1]\n",
    "theta       = cov_b_busy / var_busy\n",
    "mean_busy   = busy.mean()\n",
    "\n",
    "# adjust block indicators using the busy count control variate\n",
    "blocks_adj = blocks - theta * (busy - mean_busy)\n",
    "\n",
    "# estimate blocking probability and CI\n",
    "block_rate_cv = blocks_adj.mean()\n",
    "std_err      = blocks_adj.std(ddof=1) / np.sqrt(len(blocks_adj))\n",
    "lower_bound  = block_rate_cv - 1.96 * std_err\n",
    "upper_bound  = block_rate_cv + 1.96 * std_err\n",
    "\n",
    "print(f\"Estimated blocking fraction (with CV): {block_rate_cv:.4f}\")\n",
    "print(f\"95% CI: ({lower_bound:.4f}, {upper_bound:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4cee35",
   "metadata": {},
   "source": [
    "## 6. Common Random Numbers\n",
    "Compare Poisson vs hyper-exponential arrivals using CRN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8cfd2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean block diff (hyperexp - poisson): 0.0177\n",
      "95% CI: (0.0166, 0.0189)\n"
     ]
    }
   ],
   "source": [
    "def blocking_system_with_crn(rand_arrivals, rand_services, arrival_type=\"poisson\", servers=10, avg_service=8, customers=10000):\n",
    "    time_now = 0.0\n",
    "    blocked_count = 0\n",
    "    end_times = []\n",
    "    avg_interarrival = 1.0\n",
    "\n",
    "    for i in range(customers):\n",
    "        u_arr = rand_arrivals[i]\n",
    "        u_srv = rand_services[i]\n",
    "\n",
    "        # generate interarrival\n",
    "        if arrival_type == \"poisson\":\n",
    "            delta = -np.log(u_arr) * avg_interarrival\n",
    "        else:  # hyperexponential(0.8, rate1=0.8333; 0.2, rate2=5)\n",
    "            if u_arr < 0.8:\n",
    "                delta = -np.log(u_arr / 0.8) / 0.8333\n",
    "            else:\n",
    "                delta = -np.log((u_arr - 0.8) / 0.2) / 5.0\n",
    "\n",
    "        # generate service time\n",
    "        duration = -np.log(u_srv) * avg_service\n",
    "\n",
    "        time_now += delta\n",
    "        # remove completed services\n",
    "        end_times = [t for t in end_times if t > time_now]\n",
    "\n",
    "        if len(end_times) < servers:\n",
    "            end_times.append(time_now + duration)\n",
    "        else:\n",
    "            blocked_count += 1\n",
    "\n",
    "    return blocked_count / customers\n",
    "\n",
    "\n",
    "# Run several paired simulations\n",
    "trials = 10\n",
    "n_cust = 10000\n",
    "diffs = []\n",
    "\n",
    "for _ in range(trials):\n",
    "    uA = np.random.rand(n_cust)\n",
    "    uS = np.random.rand(n_cust)\n",
    "\n",
    "    p_block_pois = blocking_system_with_crn(uA, uS, \"poisson\", customers=n_cust)\n",
    "    p_block_hyper = blocking_system_with_crn(uA, uS, \"hyperexp\", customers=n_cust)\n",
    "\n",
    "    diffs.append(p_block_hyper - p_block_pois)\n",
    "\n",
    "# compute mean difference and 95% CI\n",
    "avg_diff = np.mean(diffs)\n",
    "std_diff = np.std(diffs, ddof=1)\n",
    "lo = avg_diff - 1.96 * std_diff / np.sqrt(trials)\n",
    "hi = avg_diff + 1.96 * std_diff / np.sqrt(trials)\n",
    "\n",
    "print(f\"Mean block diff (hyperexp - poisson): {avg_diff:.4f}\")\n",
    "print(f\"95% CI: ({lo:.4f}, {hi:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537b0dd7",
   "metadata": {},
   "source": [
    "## 7. P(Z > a) via MC & Importance Sampling\n",
    "Estimate for a=2,4 with n samples and IS N(a,σ²)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5e6559d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=2: crude=0.02200, IS=0.02294\n",
      "a=4: crude=0.00000, IS=0.00003\n"
     ]
    }
   ],
   "source": [
    "# Exercise 7: crude and IS\n",
    "def estimate_prob(a, n=10000, sigma=1):\n",
    "    z = np.random.randn(n)\n",
    "    p_crude = np.mean(z > a)\n",
    "    y = np.random.randn(n)*sigma + a\n",
    "    w = stats.norm.pdf(y)/stats.norm.pdf(y, loc=a, scale=sigma)\n",
    "    p_is = np.mean((y > a)*w)\n",
    "    return p_crude, p_is\n",
    "for a in [2,4]:\n",
    "    pc, pi = estimate_prob(a)\n",
    "    print(f\"a={a}: crude={pc:.5f}, IS={pi:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51a5a75",
   "metadata": {},
   "source": [
    "## 8. Exponential Importance Sampling\n",
    "Use g(x)=lambdae^{-lambdax} for ∫₀¹ eˣdx, find optimal lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "772ac3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.50: est=1.68943, var=5.90474e+00\n",
      "lambda=1.00: est=1.74420, var=3.44343e+00\n",
      "lambda=1.50: est=1.75814, var=3.27941e+00\n",
      "lambda=2.00: est=1.70587, var=3.70753e+00\n",
      "lambda=2.50: est=1.68618, var=4.89990e+00\n",
      "lambda=3.00: est=1.70418, var=6.82489e+00\n",
      "lambda=3.50: est=1.71947, var=9.70503e+00\n",
      "lambda=4.00: est=1.79170, var=1.51108e+01\n",
      "lambda=4.50: est=1.68284, var=2.01437e+01\n",
      "lambda=5.00: est=1.69652, var=2.59646e+01\n"
     ]
    }
   ],
   "source": [
    "# Exercise 8: Optimize lambda\n",
    "def is_exp(n, lam):\n",
    "    x = np.random.exponential(1/lam, size=n)\n",
    "    w = (np.exp(x)*(x<=1)) / (lam*np.exp(-lam*x))\n",
    "    return w.mean(), w.var(ddof=1)\n",
    "lams = np.linspace(0.5,5,10)\n",
    "results = [(lam, *is_exp(10000, lam)) for lam in lams]\n",
    "for lam, m, v in results:\n",
    "    print(f\"lambda={lam:.2f}: est={m:.5f}, var={v:.5e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82479480",
   "metadata": {},
   "source": [
    "## 9. IS Estimator for Pareto Mean\n",
    "Derive estimator using first-moment distribution and discuss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dee85c8",
   "metadata": {},
   "source": [
    "**Discussion:**\n",
    "- The IS estimator weights f(x)/g(x) where g∝x·f(x).\n",
    "- This yields a constant weight, so variance is zero in theory.\n",
    "- To cut down on variance, choose your sampling density so that you draw more points where the size of the integrand is large.\n",
    "  Concretely, pick g(x) so that it is proportional to the absolute value of h(x) multiplied by the original density f(x)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
